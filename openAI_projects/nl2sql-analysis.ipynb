{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install openai\n!pip install openai\n\nimport pandas as pd\nimport os     \nfrom openai import OpenAI\nfrom kaggle_secrets import UserSecretsClient\n\n\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"OPENAI_API_KEY\")\n\n# Set the environment variable (do NOT hardcode the key in the notebook)\nos.environ[\"OPENAI_API_KEY\"] = secret_value_0\n\n# Check whether API_KEY is\nprint(\"OPENAI_API_KEY loaded:\", bool(os.environ.get(\"OPENAI_API_KEY\")))\n\n# Create the OpenAI client (automatically read OPENAI_API_KEY)\nclient = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Medium post\n# https://medium.com/@2hyowon/from-natural-language-to-sql-in-seconds-a-lightweight-workflow-37ecb2ae5433","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# file_path example (work on Kaggle Notebook)\nfile_path = '/kaggle/input/adidas-sales-dataset/Adidas US Sales Datasets.xlsx'\n\n# Existence check (helps catch path typos early)\nassert os.path.exists(file_path), f\"File not found: {file_path}\"\n\n# Read the Excel file (Read dataset with skipping rows and dropping the first row due to the dataset format)\n# - skiprows=range(1, 4): skip extra header/notes rows if the file has them\n# - header=1: treat the second row as the column header\ndf = pd.read_excel(file_path, skiprows=range(1, 4), header=1)\ndf = df.iloc[: , 1:]     # Drop the first column\n\n# Quick shape check (rows, columns)\nprint(\"DataFrame shape:\", df.shape)\n\n# Preview the first few rows to confirm the data loaded correctly\ndf.head()\n\n# Replace spaces with underscores so columns are easier to reference in SQL\ndf.columns = [col.replace(\" \", \"_\") for col in df.columns]\n\n# Display column names to verify the cleanup\nprint(\"Columns:\", df.columns.tolist())\n\n# Check data types (useful before inserting into a database)\ndf.info()\n\n# Example Pandas Query for Sum of Sales by Region \nsales_by_region = (\n    df.groupby(\"Region\")[\"Total_Sales\"]\n      .sum()\n      .sort_values(ascending=False)\n)\n\nprint(\"Total Sales by Region (descending):\")\nprint(sales_by_region)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sqlite3\n\ntemp_db = sqlite3.connect(\":memory:\")\ndf.to_sql(name=\"Sales\", con=temp_db, if_exists=\"replace\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_schema_prompt(df):\n    \"\"\"\n    Build a minimal schema prompt for the LLM so it knows the table name and columns.\n    \"\"\"\n    # Join column names into a single comma-separated list\n    cols = \", \".join(df.columns)\n\n    prompt = f\"\"\"Given the following sqlite SQL table definition, write a SQL query\nthat answers the user's request.\n\n### sqlite SQL table, with its properties:\n# Sales({cols})\n\"\"\"\n    return prompt\n\nprint(build_schema_prompt(df))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prompt_input():\n    \"\"\"\n    Collect a natural-language request from the user (CLI input).\n    \"\"\"\n    return input(\"What would you like to analyze?: \")\n\n\n# Get the user's natural-language request (e.g., \"Show total sales by region\")\ntext_request = prompt_input()\n\n# Combine the schema context + the user request into one prompt for the LLM\nfull_prompt = f\"{build_schema_prompt(df)}\\nUser request: {text_request}\"\n\n# Preview the final prompt (helpful for debugging prompt quality)\nfull_prompt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response = client.chat.completions.create(\n  model=\"gpt-5.1\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are an assistant that generates SQL queries based on the given SQLite table definition and a natural language request. The query should start with 'SELECT' and end with a semicolon (;).\"},\n    {\"role\": \"user\", \"content\": f\"A query to answer: {full_prompt}\"},\n  ],\n\n    # Control how much \"thinking\" the model is allowed to do.\n    # gpt-5.1 supports: \"none\" | \"low\" | \"medium\" | \"high\"\n    reasoning_effort=\"none\",\n\n    # Sampling controls (ONLY supported when reasoning_effort=\"none\" for GPT-5.1 / GPT-5.2).\n    # Use temperature=0 for more deterministic SQL.\n    temperature=0,\n    # top_p=1,  # Alternative to temperature (do not set both temperature and top_p)\n\n    # Upper bound for tokens generated (includes visible output tokens + reasoning tokens).\n    max_completion_tokens = 1000\n)\n\n\n# Extract only the generated SQL text from the first completion choice.\n# (This is the raw assistant output before any post-processing/validation.)\nquery_text = response.choices[0].message.content","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_sql_response(response):\n    \"\"\"\n    Normalize the model output into a safe, executable SQLite SELECT statement.\n\n    What this function does:\n    - Reads the model-generated text from the API response\n    - Trims whitespace and normalizes formatting\n    - Ensures the query is a SELECT statement (basic guardrail)\n    - Ensures the query ends with a semicolon (;)\n    \"\"\"\n\n    # Extract the assistant's generated text (SQL) and remove leading/trailing whitespace\n    query = response.choices[0].message.content.strip()\n\n    # Basic safety/consistency check:\n    # If the model didn't start with \"SELECT\", prepend it so the output is executable SQL.\n    # (Note: for stricter safety, you could raise an error instead of auto-fixing.)\n    if not query.upper().startswith(\"SELECT\"):\n        query = \"SELECT \" + query\n\n    # Ensure the SQL statement ends with a semicolon (common requirement for execution/logging)\n    if not query.endswith(\";\"):\n        query += \";\"\n\n    # Return the normalized SQL query string\n    return query\n\n\nprint(normalize_sql_response(response))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = temp_db.execute(normalize_sql_response(response))\nprint(result.fetchall())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}